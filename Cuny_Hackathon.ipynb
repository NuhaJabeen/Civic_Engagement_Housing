{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8982073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98f4885b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data...\n",
      "Successfully retrieved 1000 rows!\n",
      "  complaint_number  status date_entered house_number    house_street zip_code  \\\n",
      "0          5189174  CLOSED   03/13/2025          141      PINE PLACE    10304   \n",
      "1          4061982  CLOSED   03/14/1997        57-20      134 STREET    11355   \n",
      "2          4931465  CLOSED   07/17/2023        31-40      100 STREET    11369   \n",
      "3          4619111  CLOSED   05/19/2015        70-04      171 STREET    11365   \n",
      "4          2365467  CLOSED   05/10/2023         1451  NEEDHAM AVENUE    10469   \n",
      "\n",
      "       bin community_board complaint_category  unit disposition_date  \\\n",
      "0  5014257             501                 7G   CSE       03/13/2025   \n",
      "1  4139091             407                 48  QNS.       04/29/1997   \n",
      "2  4034464             403                 1X  QNS.       07/18/2023   \n",
      "3  4150065             408                 05  QNS.       05/26/2015   \n",
      "4  2128765             212                 45   Q-L       06/16/2023   \n",
      "\n",
      "  disposition_code inspection_date      dobrundate special_district  \n",
      "0               I2      03/13/2025  20260227000000              NaN  \n",
      "1               I2      04/20/1997  20260227000000              NaN  \n",
      "2               I2      07/18/2023  20260227000000              NaN  \n",
      "3               H1      05/26/2015  20260227000000              NaN  \n",
      "4               C2      06/15/2023  20260227000000              NaN  \n"
     ]
    }
   ],
   "source": [
    "url = \"https://data.cityofnewyork.us/resource/eabe-havv.json?$query=SELECT%0A%20%20%60complaint_number%60%2C%0A%20%20%60status%60%2C%0A%20%20%60date_entered%60%2C%0A%20%20%60house_number%60%2C%0A%20%20%60house_street%60%2C%0A%20%20%60zip_code%60%2C%0A%20%20%60bin%60%2C%0A%20%20%60community_board%60%2C%0A%20%20%60special_district%60%2C%0A%20%20%60complaint_category%60%2C%0A%20%20%60unit%60%2C%0A%20%20%60disposition_date%60%2C%0A%20%20%60disposition_code%60%2C%0A%20%20%60inspection_date%60%2C%0A%20%20%60dobrundate%60%0AWHERE%0A%20%20%60date_entered%60%0A%20%20%20%20BETWEEN%20%2201%2F01%2F2024%2012%3A00%3A00AM%22%0A%20%20%20%20AND%20%2212%2F31%2F2024%2011%3A59%3A59%22\"\n",
    "\n",
    "print(\"Fetching data...\")\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    df_complaints = pd.DataFrame(data)\n",
    "    print(f\"Successfully retrieved {len(df_complaints)} rows!\")\n",
    "    print(df_complaints.head())\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cd95641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data...\n",
      "Error: 403\n",
      "{\n",
      "  \"code\" : \"authentication_required\",\n",
      "  \"error\" : true,\n",
      "  \"message\" : \"This request must be authenticated or have an application token\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = \"https://data.cityofnewyork.us/api/v3/views/3h2n-5cm9/query.json?query=SELECT%0A%20%20%60isn_dob_bis_viol%60%2C%0A%20%20%60boro%60%2C%0A%20%20%60bin%60%2C%0A%20%20%60block%60%2C%0A%20%20%60lot%60%2C%0A%20%20%60issue_date%60%2C%0A%20%20%60violation_type_code%60%2C%0A%20%20%60violation_number%60%2C%0A%20%20%60house_number%60%2C%0A%20%20%60street%60%2C%0A%20%20%60disposition_date%60%2C%0A%20%20%60disposition_comments%60%2C%0A%20%20%60device_number%60%2C%0A%20%20%60description%60%2C%0A%20%20%60ecb_number%60%2C%0A%20%20%60number%60%2C%0A%20%20%60violation_category%60%2C%0A%20%20%60violation_type%60\"\n",
    "\n",
    "print(\"Fetching data...\")\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    df_violations = pd.DataFrame(data)\n",
    "    print(f\"Successfully retrieved {len(df_violations)} rows!\")\n",
    "    print(df_violations.head())\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21e96230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Complaints and Violations...\n",
      "\n",
      "Comparison Success!\n",
      "         bin  boro_name  complaint_count  violation_count\n",
      "0    1000811          0              0.0              1.0\n",
      "1    1000854          0              0.0              1.0\n",
      "2    1000865  MANHATTAN              1.0              0.0\n",
      "3    1001021  MANHATTAN              1.0              0.0\n",
      "4    1001033  MANHATTAN              1.0              0.0\n",
      "..       ...        ...              ...              ...\n",
      "995  3142329          0              0.0              2.0\n",
      "996  3142470   BROOKLYN              1.0              0.0\n",
      "997  3142537          0              0.0              1.0\n",
      "998  3144131   BROOKLYN              1.0              0.0\n",
      "999  3144195          0              0.0              1.0\n",
      "\n",
      "[1000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# URLs for your filtered endpoints\n",
    "complaints_url = \"https://data.cityofnewyork.us/resource/eabe-havv.json?$query=SELECT%20complaint_number,%20status,%20date_entered,%20bin,%20complaint_category%20WHERE%20date_entered%20BETWEEN%20%2201/01/2024%2012:00:00AM%22%20AND%20%2212/31/2024%2011:59:59PM%22\"\n",
    "violations_url = \"https://data.cityofnewyork.us/resource/3h2n-5cm9.json?$query=SELECT%20isn_dob_bis_viol,%20boro,%20bin,%20issue_date,%20violation_type,%20description%20WHERE%20issue_date%20BETWEEN%20%2220240101%22%20AND%20%2220241231%22\"\n",
    "\n",
    "print(\"Fetching Complaints and Violations...\")\n",
    "\n",
    "# Get Data\n",
    "r_comp = requests.get(complaints_url)\n",
    "r_viol = requests.get(violations_url)\n",
    "\n",
    "if r_comp.status_code == 200 and r_viol.status_code == 200:\n",
    "    df_comp = pd.DataFrame(r_comp.json())\n",
    "    df_viol = pd.DataFrame(r_viol.json())\n",
    "    \n",
    "    # Standardize Borough names in Violations (Boro codes: 1=MN, 2=BX, 3=BK, 4=QN, 5=SI)\n",
    "    boro_map = {'1': 'MANHATTAN', '2': 'BRONX', '3': 'BROOKLYN', '4': 'QUEENS', '5': 'STATEN ISLAND'}\n",
    "    df_viol['boro_name'] = df_viol['boro'].map(boro_map)\n",
    "    \n",
    "    # Fix Complaint Boroughs (extracting from BIN first digit as discussed)\n",
    "    df_comp['boro_name'] = df_comp['bin'].str[0].map(boro_map)\n",
    "\n",
    "    # --- THE COMPARISON ---\n",
    "    # Group by BIN to see how many complaints vs violations per building\n",
    "    comp_stats = df_comp.groupby(['bin', 'boro_name']).size().reset_index(name='complaint_count')\n",
    "    viol_stats = df_viol.groupby('bin').size().reset_index(name='violation_count')\n",
    "\n",
    "    # Join the two datasets on 'bin'\n",
    "    # 'outer' join ensures we see buildings that have ONLY complaints OR ONLY violations\n",
    "    comparison = pd.merge(comp_stats, viol_stats, on='bin', how='outer').fillna(0)\n",
    "\n",
    "    print(\"\\nComparison Success!\")\n",
    "    print(comparison.head(1000))\n",
    "    \n",
    "else:\n",
    "    print(\"Error fetching data. Check your API limits or URLs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "435fc53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boro_name\n",
      "0                 0.000000\n",
      "BRONX             9.914966\n",
      "BROOKLYN         10.000000\n",
      "MANHATTAN         9.836875\n",
      "QUEENS           10.033670\n",
      "STATEN ISLAND    10.000000\n",
      "Name: ratio, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create a conversion ratio\n",
    "comparison['ratio'] = comparison['complaint_count'] / (comparison['violation_count'] + 0.1) # +0.1 to avoid divide by zero\n",
    "avg_efficiency = comparison.groupby('boro_name')['ratio'].mean()\n",
    "print(avg_efficiency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316775e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching live 2024 data from NYC Open Data...\n",
      "Error fetching data. Check your connection.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'borough_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     31\u001b[39m df_viol[\u001b[33m'\u001b[39m\u001b[33missue_date\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(df_viol[\u001b[33m'\u001b[39m\u001b[33missue_date\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Cell 3: Comparison Logic\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Group by BIN to find building-level patterns\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m comp_stats = \u001b[43mdf_comp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbin\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mborough_name\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m.size().reset_index(name=\u001b[33m'\u001b[39m\u001b[33mcomplaint_count\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     36\u001b[39m viol_stats = df_viol.groupby(\u001b[33m'\u001b[39m\u001b[33mbin\u001b[39m\u001b[33m'\u001b[39m).size().reset_index(name=\u001b[33m'\u001b[39m\u001b[33mviolation_count\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Merge datasets to see the 'Gap'\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\klmic\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\util\\_decorators.py:336\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    331\u001b[39m     warnings.warn(\n\u001b[32m    332\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    333\u001b[39m         klass,\n\u001b[32m    334\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    335\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\klmic\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\frame.py:10817\u001b[39m, in \u001b[36mDataFrame.groupby\u001b[39m\u001b[34m(self, by, level, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m  10814\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m  10815\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou have to supply one of \u001b[39m\u001b[33m'\u001b[39m\u001b[33mby\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m> \u001b[39m\u001b[32m10817\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  10818\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m  10819\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10820\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10821\u001b[39m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10822\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10823\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10824\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10825\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10826\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\klmic\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1095\u001b[39m, in \u001b[36mGroupBy.__init__\u001b[39m\u001b[34m(self, obj, keys, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28mself\u001b[39m.dropna = dropna\n\u001b[32m   1094\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1095\u001b[39m     grouper, exclusions, obj = \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1096\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1097\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1098\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1099\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1100\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1101\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1102\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1104\u001b[39m \u001b[38;5;28mself\u001b[39m.observed = observed\n\u001b[32m   1105\u001b[39m \u001b[38;5;28mself\u001b[39m.obj = obj\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\klmic\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:901\u001b[39m, in \u001b[36mget_grouper\u001b[39m\u001b[34m(obj, key, level, sort, observed, validate, dropna)\u001b[39m\n\u001b[32m    899\u001b[39m         in_axis, level, gpr = \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    900\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m901\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[32m    902\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr.key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    903\u001b[39m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[32m    904\u001b[39m     exclusions.add(gpr.key)\n",
      "\u001b[31mKeyError\u001b[39m: 'borough_name'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# URLs for your 2024 filtered endpoints\n",
    "complaints_url = \"https://data.cityofnewyork.us/resource/eabe-havv.json?$query=SELECT%20complaint_number,%20status,%20date_entered,%20bin,%20complaint_category%20WHERE%20date_entered%20BETWEEN%20%2201/01/2024%2012:00:00AM%22%20AND%20%2212/31/2024%2011:59:59PM%22&$limit=50000\"\n",
    "violations_url = \"https://data.cityofnewyork.us/resource/3h2n-5cm9.json?$query=SELECT%20isn_dob_bis_viol,%20boro,%20bin,%20issue_date,%20violation_type,%20description%20WHERE%20issue_date%20BETWEEN%20%2220240101%22%20AND%20%2220241231%22&$limit=50000\"\n",
    "\n",
    "print(\"Fetching live 2024 data from NYC Open Data...\")\n",
    "r_comp = requests.get(complaints_url)\n",
    "r_viol = requests.get(violations_url)\n",
    "\n",
    "if r_comp.status_code == 200 and r_viol.status_code == 200:\n",
    "    df_comp = pd.DataFrame(r_comp.json())\n",
    "    df_viol = pd.DataFrame(r_viol.json())\n",
    "    print(f\"Loaded {len(df_comp)} Complaints and {len(df_viol)} Violations.\")\n",
    "else:\n",
    "    print(\"Error fetching data. Check your connection.\")\n",
    "\n",
    "# Cell 2: The Borough Fix & Data Cleaning\n",
    "# Mapping Boro codes (1=MN, 2=BX, 3=BK, 4=QN, 5=SI)\n",
    "boro_map = {'1': 'MANHATTAN', '2': 'BRONX', '3': 'BROOKLYN', '4': 'QUEENS', '5': 'STATEN ISLAND'}\n",
    "\n",
    "# Apply the fix: Extracting Borough from BIN (first digit)\n",
    "df_comp['borough_name'] = df_comp['bin'].str[0].map(boro_map)\n",
    "df_viol['borough_name'] = df_viol['boro'].map(boro_map) # Violations uses 'boro' column\n",
    "\n",
    "# Ensure dates are usable\n",
    "df_comp['date_entered'] = pd.to_datetime(df_comp['date_entered'])\n",
    "df_viol['issue_date'] = pd.to_datetime(df_viol['issue_date'])\n",
    "\n",
    "# Cell 3: Comparison Logic\n",
    "# Group by BIN to find building-level patterns\n",
    "comp_stats = df_comp.groupby(['bin', 'borough_name']).size().reset_index(name='complaint_count')\n",
    "viol_stats = df_viol.groupby('bin').size().reset_index(name='violation_count')\n",
    "\n",
    "# Merge datasets to see the 'Gap'\n",
    "comparison = pd.merge(comp_stats, viol_stats, on='bin', how='outer').fillna(0)\n",
    "comparison['conversion_rate'] = (comparison['violation_count'] / comparison['complaint_count']) * 100\n",
    "\n",
    "#The Accountability Gap\n",
    "plt.style.use('fivethirtyeight')\n",
    "plot_data = comparison.groupby('borough_name')[['complaint_count', 'violation_count']].sum()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "plot_data.plot(kind='bar', ax=ax, color=['#3498db', '#e74c3c'], width=0.8)\n",
    "ax.set_title('NYC Housing: Total Complaints vs. Total Violations (2024)', fontsize=16)\n",
    "ax.set_ylabel('Count')\n",
    "ax.legend(['Residents Complaining', 'City Issuing Violations'])\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "#Conversion Rate (Efficiency)\n",
    "stats_summary = comparison.groupby('borough_name').sum()\n",
    "stats_summary['conversion_pct'] = (stats_summary['violation_count'] / stats_summary['complaint_count']) * 100\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=stats_summary.index, y=stats_summary['conversion_pct'], palette='magma')\n",
    "plt.title('Conversion Rate: % of Complaints that become Violations')\n",
    "plt.ylabel('Conversion %')\n",
    "plt.show()\n",
    "\n",
    "# Buildings with highest complaints but ZERO violations\n",
    "neglected = comparison[comparison['violation_count'] == 0].sort_values(by='complaint_count', ascending=False)\n",
    "print(\"TOP 5 BUILDINGS WITH NO ACCOUNTABILITY (High Complaints / Zero Violations):\")\n",
    "print(neglected[['bin', 'borough_name', 'complaint_count']].head(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
